{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1B5FoZeNn92"
      },
      "source": [
        "import tensorflow.keras"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVJ9PSEBNypR",
        "outputId": "95a573fe-e293-42c7-dd47-845bb737ebad"
      },
      "source": [
        "import tensorflow.keras as keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "latent_dim = 32\r\n",
        "height = 32\r\n",
        "width = 32\r\n",
        "channels = 3\r\n",
        "\r\n",
        "generator_input = keras.Input(shape=(latent_dim,))\r\n",
        "\r\n",
        "x = layers.Dense(128 * 16 * 16)(generator_input)\r\n",
        "x = layers.LeakyReLU()(x)\r\n",
        "x = layers.Reshape((16, 16, 128))(x)\r\n",
        "\r\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\r\n",
        "x = layers.LeakyReLU()(x)\r\n",
        "\r\n",
        "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\r\n",
        "x = layers.LeakyReLU()(x)\r\n",
        "\r\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\r\n",
        "x = layers.LeakyReLU()(x)\r\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\r\n",
        "x = layers.LeakyReLU()(x)\r\n",
        "\r\n",
        "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\r\n",
        "generator = keras.models.Model(generator_input, x)\r\n",
        "generator.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32)]              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32768)             1081344   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 256)       819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 3)         37635     \n",
            "=================================================================\n",
            "Total params: 6,264,579\n",
            "Trainable params: 6,264,579\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6XPurh4N1RY",
        "outputId": "75c85ef3-70fb-464f-beab-f1ad5745368d"
      },
      "source": [
        "discriminator_input = layers.Input(shape=(height, width, channels))\r\n",
        "x = layers.Conv2D(128, 3)(discriminator_input)\r\n",
        "x = layers.LeakyReLU()(x)\r\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\r\n",
        "x = layers.LeakyReLU()(x)\r\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\r\n",
        "x = layers.LeakyReLU()(x)\r\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\r\n",
        "x = layers.LeakyReLU()(x)\r\n",
        "x = layers.Flatten()(x)\r\n",
        "\r\n",
        "# 드롭아웃 층을 넣는 것이 중요\r\n",
        "x = layers.Dropout(0.4)(x)\r\n",
        "\r\n",
        "# 분류 층\r\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\r\n",
        "\r\n",
        "discriminator = keras.models.Model(discriminator_input, x)\r\n",
        "discriminator.summary()\r\n",
        "\r\n",
        "# 옵티마이저에서 (값을 지정하여) 그래디언트 클리핑을 사용\r\n",
        "# 안정된 훈련을 위해서 학습률 감쇠를 사용\r\n",
        "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\r\n",
        "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 14, 14, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 6, 6, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 2, 2, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 790,913\n",
            "Trainable params: 790,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_1iYOqxN8UZ"
      },
      "source": [
        "discriminator.trainable = False\r\n",
        "\r\n",
        "gan_input = keras.Input(shape=(latent_dim,))\r\n",
        "gan_output = discriminator(generator(gan_input))\r\n",
        "gan = keras.models.Model(gan_input, gan_output)\r\n",
        "\r\n",
        "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\r\n",
        "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1_ToKwabkEv",
        "outputId": "cfc23c4b-32b9-436d-c687-66f9557e6c08"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfy0edUHN-Ki",
        "outputId": "52cf83c8-f55d-4a57-df29-a96f2dad66bc"
      },
      "source": [
        "import os\r\n",
        "from keras.preprocessing import image\r\n",
        "\r\n",
        "# CIFAR10 데이터를 로드\r\n",
        "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\r\n",
        "\r\n",
        "# 개구리 이미지를 선택(클래스 6)\r\n",
        "x_train = x_train[y_train.flatten() == 6]\r\n",
        "\r\n",
        "# 데이터를 정규화\r\n",
        "x_train = x_train.reshape(\r\n",
        "    (x_train.shape[0],) + (height, width, channels)).astype('float32') / 255.\r\n",
        "\r\n",
        "iterations = 10000\r\n",
        "batch_size = 20\r\n",
        "save_dir = '/content/gdrive/My Drive/Colab Notebooks/datasets'\r\n",
        "if not os.path.exists(save_dir): os.mkdir(save_dir)\r\n",
        "\r\n",
        "# 훈련 반복 \r\n",
        "start = 0\r\n",
        "for step in range(iterations):\r\n",
        "    # 잠재 공간에서 무작위로 포인트를 샘플링\r\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\r\n",
        "\r\n",
        "    # 가짜 이미지를 디코딩\r\n",
        "    generated_images = generator.predict(random_latent_vectors)\r\n",
        "\r\n",
        "    # 진짜 이미지와 연결\r\n",
        "    stop = start + batch_size\r\n",
        "    real_images = x_train[start: stop]\r\n",
        "    combined_images = np.concatenate([generated_images, real_images])\r\n",
        "\r\n",
        "    # 진짜와 가짜 이미지를 구분하여 레이블을 합침\r\n",
        "    labels = np.concatenate([np.ones((batch_size, 1)),\r\n",
        "                             np.zeros((batch_size, 1))])\r\n",
        "    # 레이블에 랜덤 노이즈를 추가 아주 중요\r\n",
        "    labels += 0.05 * np.random.random(labels.shape)\r\n",
        "\r\n",
        "    # discriminator를 훈련\r\n",
        "    d_loss = discriminator.train_on_batch(combined_images, labels)\r\n",
        "\r\n",
        "    # 잠재 공간에서 무작위로 포인트를 샘플링\r\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\r\n",
        "\r\n",
        "    # 모두 “진짜 이미지\"라고 레이블을 만든다\r\n",
        "    misleading_targets = np.zeros((batch_size, 1))\r\n",
        "\r\n",
        "    # generator를 훈련(gan 모델에서 discriminator의 가중치는 동결)\r\n",
        "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\r\n",
        "    \r\n",
        "    start += batch_size\r\n",
        "    if start > len(x_train) - batch_size:\r\n",
        "      start = 0\r\n",
        "\r\n",
        "    # 중간 중간 저장하고 그래프 그리기\r\n",
        "    if step % 100 == 0:\r\n",
        "        # 모델 가중치를 저장\r\n",
        "        gan.save_weights('gan.h5')\r\n",
        "\r\n",
        "        # 측정 지표를 출력\r\n",
        "        print('스텝 %s에서 판별자 손실: %s' % (step, d_loss))\r\n",
        "        print('스텝 %s에서 적대적 손실: %s' % (step, a_loss))\r\n",
        "\r\n",
        "        # 생성된 이미지 하나를 저장\r\n",
        "        img = image.array_to_img(generated_images[0] * 255., scale=False)\r\n",
        "        img.save(os.path.join(save_dir, 'generated_frog' + str(step) + '.png'))\r\n",
        "\r\n",
        "        # 비교를 위해 진짜 이미지 하나를 저장\r\n",
        "        img = image.array_to_img(real_images[0] * 255., scale=False)\r\n",
        "        img.save(os.path.join(save_dir, 'real_frog' + str(step) + '.png'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 8s 0us/step\n",
            "스텝 0에서 판별자 손실: 0.7072015404701233\n",
            "스텝 0에서 적대적 손실: 0.6965011358261108\n",
            "스텝 100에서 판별자 손실: 0.7300525903701782\n",
            "스텝 100에서 적대적 손실: 1.055509328842163\n",
            "스텝 200에서 판별자 손실: 0.716961681842804\n",
            "스텝 200에서 적대적 손실: 0.7434946298599243\n",
            "스텝 300에서 판별자 손실: 0.6976760625839233\n",
            "스텝 300에서 적대적 손실: 0.9260934591293335\n",
            "스텝 400에서 판별자 손실: 1.120772123336792\n",
            "스텝 400에서 적대적 손실: 1.3289258480072021\n",
            "스텝 500에서 판별자 손실: 0.6897364854812622\n",
            "스텝 500에서 적대적 손실: 0.7432699799537659\n",
            "스텝 600에서 판별자 손실: 0.6878669857978821\n",
            "스텝 600에서 적대적 손실: 0.778958797454834\n",
            "스텝 700에서 판별자 손실: 0.692776620388031\n",
            "스텝 700에서 적대적 손실: 0.7870019674301147\n",
            "스텝 800에서 판별자 손실: 0.68816739320755\n",
            "스텝 800에서 적대적 손실: 0.753649890422821\n",
            "스텝 900에서 판별자 손실: 0.6823932528495789\n",
            "스텝 900에서 적대적 손실: 0.9310010075569153\n",
            "스텝 1000에서 판별자 손실: 0.6858614683151245\n",
            "스텝 1000에서 적대적 손실: 0.7715394496917725\n",
            "스텝 1100에서 판별자 손실: 0.6972100734710693\n",
            "스텝 1100에서 적대적 손실: 0.7343355417251587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHrrN47ugZ1T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLvy-9WhO29d"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ANKzhOzV36y"
      },
      "source": [
        "random_latent_vectors = np.random.normal(size=(10, latent_dim))\r\n",
        "\r\n",
        "# 가짜 이미지로 디코딩\r\n",
        "generated_images = generator.predict(random_latent_vectors)\r\n",
        "\r\n",
        "for i in range(generated_images.shape[0]):\r\n",
        "    img = image.array_to_img(generated_images[i] * 255., scale=False)\r\n",
        "    plt.figure()\r\n",
        "    plt.imshow(img)\r\n",
        "    \r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}